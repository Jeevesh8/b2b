# Back-2-Back Translation
## Dataset 

  The dataset used is [WMT-14 en-de](https://nlp.stanford.edu/projects/nmt/) .

## Model

![Back2Back](https://github.com/NLP-Research-Group-DTU/b2b/blob/After-Paper/images/Back2Back22.png)

## Training

See [colab notebook](https://github.com/deterministic-algorithms-lab/Back-2-Back-Translation/blob/After-Paper/TrainB2B.ipynb)

## Results 
Learning from Explanations with Neural Execution Tree
